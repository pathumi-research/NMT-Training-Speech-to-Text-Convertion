{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1WOaJIQ_BXc58CQ6DMr14RxSJcQtZ-eow","authorship_tag":"ABX9TyM4SH6H5wJPNyhOCL6CzHlc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"aae2ef9f467848e78917da067e8d27dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_20d74f8cc2274b3cbfdf594814f69701","IPY_MODEL_2efdb698bc7b4dd8a44b9b48754667ae","IPY_MODEL_f831599b899d493382f121ebe26e7d19"],"layout":"IPY_MODEL_f60a78d4bb1d46d09a4c458d061506de"}},"20d74f8cc2274b3cbfdf594814f69701":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6a8932ae7704369bff40a1b9b84115e","placeholder":"‚Äã","style":"IPY_MODEL_e0f0d37ccb9b4c2bb6b1f78ff7456a6e","value":"Map:‚Äá100%"}},"2efdb698bc7b4dd8a44b9b48754667ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0f08917098040689732100853ffd7d9","max":103437,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0cd80404f67d434985ed54527a1e0d96","value":103437}},"f831599b899d493382f121ebe26e7d19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_493e346c1a3844f998d3c3eb11521681","placeholder":"‚Äã","style":"IPY_MODEL_874e2d79ebdd4f0db7175a112a0b936e","value":"‚Äá103437/103437‚Äá[00:24&lt;00:00,‚Äá4534.66‚Äáexamples/s]"}},"f60a78d4bb1d46d09a4c458d061506de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6a8932ae7704369bff40a1b9b84115e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0f0d37ccb9b4c2bb6b1f78ff7456a6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0f08917098040689732100853ffd7d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cd80404f67d434985ed54527a1e0d96":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"493e346c1a3844f998d3c3eb11521681":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"874e2d79ebdd4f0db7175a112a0b936e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a0ed64ef468490bab2df135877b680a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0bc5e67f3f7f4ee8b8e22a6b01f38763","IPY_MODEL_631eb8f565844974b75f10a98d937100","IPY_MODEL_434677c1d9124ac5a9a797a9e4736eff"],"layout":"IPY_MODEL_220b7ce39d01471ebb309d00516abf6b"}},"0bc5e67f3f7f4ee8b8e22a6b01f38763":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a4a5a5f11eb453da3c7a649bb3558dc","placeholder":"‚Äã","style":"IPY_MODEL_5369e9eda67445519a5a5d75fbedc3eb","value":"Map:‚Äá100%"}},"631eb8f565844974b75f10a98d937100":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_78d83b0c0d2b47238911b718f63d77ff","max":11494,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52efecb947384e3497fcaf172eed48f9","value":11494}},"434677c1d9124ac5a9a797a9e4736eff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75b67d4958f64745853336332027342e","placeholder":"‚Äã","style":"IPY_MODEL_212d71708c83426192febe8b96753632","value":"‚Äá11494/11494‚Äá[00:02&lt;00:00,‚Äá4972.73‚Äáexamples/s]"}},"220b7ce39d01471ebb309d00516abf6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a4a5a5f11eb453da3c7a649bb3558dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5369e9eda67445519a5a5d75fbedc3eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78d83b0c0d2b47238911b718f63d77ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52efecb947384e3497fcaf172eed48f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75b67d4958f64745853336332027342e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"212d71708c83426192febe8b96753632":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"],"metadata":{"id":"y-9_UI7xaXlc","executionInfo":{"status":"ok","timestamp":1764305499502,"user_tz":-330,"elapsed":132,"user":{"displayName":"Pathumi Ahinsa","userId":"00611856141901815530"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"nakd2XlpXcKN","executionInfo":{"status":"ok","timestamp":1764305549381,"user_tz":-330,"elapsed":49876,"user":{"displayName":"Pathumi Ahinsa","userId":"00611856141901815530"}}},"outputs":[],"source":["# ====================================================================\n","# STEP 0: Setup and Installation\n","# ====================================================================\n","\n","# Install necessary libraries (if running in a fresh environment like Colab)\n","# !pip install transformers datasets sentencepiece accelerate -q\n","\n","import torch\n","import re\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from datasets import Dataset\n","from transformers import (\n","    M2M100ForConditionalGeneration,\n","    M2M100Tokenizer,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq,\n","\n",")\n","from torch.optim import AdamW   # ADD THIS"]},{"cell_type":"code","source":["# Set up CUDA if a GPU is available (highly recommended for Transformers)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","# torch.cuda.empty_cache() # Use this line if you encounter memory issues\n","\n","# Define File Path (Adjust if necessary)\n","FILE_PATH = \"/content/drive/MyDrive/research/model/merged_f.txt\"\n","OUTPUT_DIR = \"/content/drive/MyDrive/research/model/m2m100_finetuned\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fubzEsVVZtTo","executionInfo":{"status":"ok","timestamp":1764305549406,"user_tz":-330,"elapsed":17,"user":{"displayName":"Pathumi Ahinsa","userId":"00611856141901815530"}},"outputId":"3feb014f-2867-4128-cb06-3b386808e435"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["# ====================================================================\n","# STEP 1: Data Loading, Splitting, and Initial Dataset Creation\n","# ====================================================================\n","\n","src_texts = []\n","tgt_texts = []\n","\n","print(\"1. Loading and parsing data...\")\n","try:\n","    with open(FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            if \"@\" in line:\n","                parts = line.strip().split(\"@\")\n","                if len(parts) == 2:\n","                    # Source (Sinhala Text) is before '@'\n","                    src_texts.append(parts[0].strip())\n","                    # Target (Gloss IDs/Text) is after '@'\n","                    tgt_texts.append(parts[1].strip())\n","except FileNotFoundError:\n","    print(f\"Error: File not found at {FILE_PATH}. Please check your path.\")\n","    # Exit or use dummy data for testing if path is wrong\n","\n","print(f\"Total samples loaded: {len(src_texts)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_ZSdy6JZZ_V","executionInfo":{"status":"ok","timestamp":1764305551685,"user_tz":-330,"elapsed":2281,"user":{"displayName":"Pathumi Ahinsa","userId":"00611856141901815530"}},"outputId":"88932c94-58a8-4e11-f5c0-66c1ebc32af1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["1. Loading and parsing data...\n","Total samples loaded: 114931\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Split data: 90% Train, 10% Eval\n","train_src, eval_src, train_tgt, eval_tgt = train_test_split(\n","    src_texts, tgt_texts, test_size=0.1, random_state=42\n",")\n","\n","# Create Hugging Face Dataset objects\n","train_dataset = Dataset.from_dict({\"source\": train_src, \"target\": train_tgt})\n","eval_dataset = Dataset.from_dict({\"source\": eval_src, \"target\": eval_tgt})\n","\n","print(f\"Training samples: {len(train_dataset)}\")\n","print(f\"Evaluation samples: {len(eval_dataset)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5wXIaEj6BcE","executionInfo":{"status":"ok","timestamp":1764305551978,"user_tz":-330,"elapsed":289,"user":{"displayName":"Pathumi Ahinsa","userId":"00611856141901815530"}},"outputId":"c59bce4d-146a-4423-a9f0-178599d4815c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Training samples: 103437\n","Evaluation samples: 11494\n"]}]},{"cell_type":"code","source":["import os\n","from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n","\n","# 1. Define a permanent path in your Google Drive\n","# This is where the base model files will sit\n","model_save_path = \"/content/drive/MyDrive/research/model/m2m100_base_saved\"\n","\n","MODEL_NAME = \"facebook/m2m100_418M\"\n","print(f\"\\n2. Initializing model...\")\n","\n","# 2. Check if the model already exists in your Drive\n","if os.path.exists(model_save_path):\n","    print(f\"üìÇ Found saved model in Drive. Loading from: {model_save_path}\")\n","    # Load directly from Drive (Fast!)\n","    model = M2M100ForConditionalGeneration.from_pretrained(model_save_path).to(device)\n","    tokenizer = M2M100Tokenizer.from_pretrained(model_save_path)\n","\n","else:\n","    print(f\"‚¨áÔ∏è Model not found in Drive. Downloading from Hugging Face: {MODEL_NAME}\")\n","    # Download from Internet\n","    model = M2M100ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n","    tokenizer = M2M100Tokenizer.from_pretrained(MODEL_NAME)\n","\n","    # Save to Drive for next time\n","    print(f\"üíæ Saving model to Drive for future use...\")\n","    model.save_pretrained(model_save_path)\n","    tokenizer.save_pretrained(model_save_path)\n","\n","# 3. Set Languages\n","# We explicitly set these every time just to be safe\n","tokenizer.src_lang = \"si\"\n","tokenizer.tgt_lang = \"si\"\n","print(f\"Tokenizer set for src_lang: {tokenizer.src_lang} and tgt_lang: {tokenizer.tgt_lang}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYjccOFAX9Om","executionInfo":{"status":"ok","timestamp":1764305593156,"user_tz":-330,"elapsed":41175,"user":{"displayName":"Pathumi Ahinsa","userId":"00611856141901815530"}},"outputId":"ae95682c-485b-439b-e73e-9a0f7d83401d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","2. Initializing model...\n","üìÇ Found saved model in Drive. Loading from: /content/drive/MyDrive/research/model/m2m100_base_saved\n","Tokenizer set for src_lang: si and tgt_lang: si\n"]}]},{"cell_type":"code","source":["# ====================================================================\n","# STEP 3: Vocabulary Adaptation for Target Gloss Tokens\n","# (Crucial for handling the SSL/Gloss output)\n","# ====================================================================\n","\n","print(\"\\n3. Adapting vocabulary for Gloss tokens...\")\n","\n","# 3.1 Extract unique Gloss Tokens from your target data\n","unique_gloss_tokens = set()\n","all_tgt_texts = train_tgt + eval_tgt\n","\n","for text in all_tgt_texts:\n","    # Target format: 'ID:GLOSS_WORD|ID:GLOSS_WORD|...'\n","    parts = text.split('|')\n","    for part in parts:\n","        if ':' in part:\n","            # Take everything after the first ':' (which is the Gloss word)\n","            gloss_token = part.split(':', 1)[1]\n","            unique_gloss_tokens.add(gloss_token.strip())\n","\n","unique_gloss_tokens_list = list(unique_gloss_tokens)\n","print(f\"Identified {len(unique_gloss_tokens_list)} unique Gloss tokens.\")\n","\n","# 3.2 Add new tokens and resize model embeddings\n","num_added_toks = tokenizer.add_tokens(unique_gloss_tokens_list)\n","print(f\"Added {num_added_toks} new tokens to the tokenizer.\")\n","\n","# Resize the model embeddings to include the new tokens.\n","# The new embeddings for these tokens are randomly initialized.\n","model.resize_token_embeddings(len(tokenizer))\n","print(f\"Model vocabulary size resized to: {len(tokenizer)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fIeKBpA_aS1z","executionInfo":{"status":"ok","timestamp":1764305595017,"user_tz":-330,"elapsed":1858,"user":{"displayName":"Pathumi Ahinsa","userId":"00611856141901815530"}},"outputId":"5a4b69d6-825f-4dad-ec7c-7592dc321a78"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","3. Adapting vocabulary for Gloss tokens...\n","Identified 3479 unique Gloss tokens.\n"]},{"output_type":"stream","name":"stderr","text":["The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"]},{"output_type":"stream","name":"stdout","text":["Added 3410 new tokens to the tokenizer.\n","Model vocabulary size resized to: 131514\n"]}]},{"cell_type":"code","source":["# ====================================================================\n","# STEP 4: Tokenization Function and Dataset Mapping\n","# ====================================================================\n","\n","MAX_SEQ_LENGTH = 128\n","\n","def preprocess_function(examples):\n","    inputs = examples[\"source\"]\n","    targets = examples[\"target\"]\n","\n","    # Tokenize inputs (Source - Sinhala Text)\n","    model_inputs = tokenizer(inputs, max_length=MAX_SEQ_LENGTH, truncation=True)\n","\n","    # Tokenize targets (Labels - Gloss Text)\n","    # The context manager ensures the tokenizer uses the target language settings.\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(targets, max_length=MAX_SEQ_LENGTH, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","# Apply tokenization to datasets\n","tokenized_train = train_dataset.map(preprocess_function, batched=True)\n","tokenized_eval = eval_dataset.map(preprocess_function, batched=True)\n","\n","# Remove original columns that are no longer needed\n","tokenized_train = tokenized_train.remove_columns([\"source\", \"target\"])\n","tokenized_eval = tokenized_eval.remove_columns([\"source\", \"target\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["aae2ef9f467848e78917da067e8d27dd","20d74f8cc2274b3cbfdf594814f69701","2efdb698bc7b4dd8a44b9b48754667ae","f831599b899d493382f121ebe26e7d19","f60a78d4bb1d46d09a4c458d061506de","f6a8932ae7704369bff40a1b9b84115e","e0f0d37ccb9b4c2bb6b1f78ff7456a6e","e0f08917098040689732100853ffd7d9","0cd80404f67d434985ed54527a1e0d96","493e346c1a3844f998d3c3eb11521681","874e2d79ebdd4f0db7175a112a0b936e","9a0ed64ef468490bab2df135877b680a","0bc5e67f3f7f4ee8b8e22a6b01f38763","631eb8f565844974b75f10a98d937100","434677c1d9124ac5a9a797a9e4736eff","220b7ce39d01471ebb309d00516abf6b","2a4a5a5f11eb453da3c7a649bb3558dc","5369e9eda67445519a5a5d75fbedc3eb","78d83b0c0d2b47238911b718f63d77ff","52efecb947384e3497fcaf172eed48f9","75b67d4958f64745853336332027342e","212d71708c83426192febe8b96753632"]},"id":"3RYLxQRRaWzn","executionInfo":{"status":"ok","timestamp":1764305624641,"user_tz":-330,"elapsed":29618,"user":{"displayName":"Pathumi Ahinsa","userId":"00611856141901815530"}},"outputId":"01c97e28-612c-4a92-867b-9cdd93245123"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/103437 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aae2ef9f467848e78917da067e8d27dd"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4118: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/11494 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a0ed64ef468490bab2df135877b680a"}},"metadata":{}}]},{"cell_type":"code","source":["# ====================================================================\n","# STEP 5: Differential Learning Rate Configuration\n","# (Implementing the paper's strategy)\n","# ====================================================================\n","\n","print(\"\\n4. Configuring Differential Learning Rates...\")\n","\n","# Differential LRs based on the paper:\n","LR_NEW_WEIGHTS = 1.0e-3 # For newly initialized/resized embeddings and output head\n","LR_PRE_TRAINED = 2.0e-5 # For the core pre-trained layers (Encoder/Decoder)\n","\n","# Separate parameters into two groups\n","# Group 1: Pre-trained layers (core Encoder/Decoder) -> SMALL LR\n","pretrained_params = [\n","    p for n, p in model.named_parameters() if p.requires_grad and not any(ext in n for ext in [\"embed\", \"lm_head\"])\n","]\n","\n","# Group 2: Newly resized embeddings and output head -> LARGER LR\n","# 'embed' for input/output embeddings, 'lm_head' for the final classification layer\n","new_params = [\n","    p for n, p in model.named_parameters() if p.requires_grad and any(ext in n for ext in [\"embed\", \"lm_head\"])\n","]\n","\n","# Define the parameter groups for the optimizer\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": pretrained_params,\n","        \"lr\": LR_PRE_TRAINED,\n","        \"weight_decay\": 0.01\n","    },\n","    {\n","        \"params\": new_params,\n","        \"lr\": LR_NEW_WEIGHTS,\n","        \"weight_decay\": 0.01\n","    },\n","]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"877ct_Zfc-2X","executionInfo":{"status":"ok","timestamp":1764305624707,"user_tz":-330,"elapsed":43,"user":{"displayName":"Pathumi Ahinsa","userId":"00611856141901815530"}},"outputId":"6c5698dc-b61e-4163-d003-581515675ee0"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","4. Configuring Differential Learning Rates...\n"]}]},{"cell_type":"code","source":["# ====================================================================\n","# STEP 6: Setup Trainer Arguments and Initialization\n","# ====================================================================\n","\n","BATCH_SIZE = 4\n","NUM_EPOCHS = 10\n","SAVE_STEPS = 500\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","# Training Arguments\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    num_train_epochs=NUM_EPOCHS,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    gradient_accumulation_steps=8, # <--- ADD GRADIENT ACCUMULATION (4 * 8 = 32 effective)\n","    warmup_ratio=5/NUM_EPOCHS,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=100,\n","    report_to=\"none\",\n","\n","    # Checkpointing Configuration\n","    save_strategy=\"steps\",\n","    save_steps=SAVE_STEPS,\n","    save_total_limit=3,\n","    eval_strategy=\"epoch\",\n","    load_best_model_at_end=False,\n","    metric_for_best_model=\"eval_loss\",\n","    greater_is_better=False,\n","    predict_with_generate=True,\n","\n","    learning_rate=LR_PRE_TRAINED,\n",")\n","\n","# Initialize Trainer.\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_eval,\n","    tokenizer=tokenizer,\n","    # processing_class=M2M100Tokenizer,\n","    data_collator=data_collator,\n","    # Ensure you imported AdamW from torch.optim as discussed before\n","    optimizers=(AdamW(optimizer_grouped_parameters, eps=1e-6), None),\n",")"],"metadata":{"id":"Wx1QEy2_xZTt","executionInfo":{"status":"ok","timestamp":1764307399405,"user_tz":-330,"elapsed":15,"user":{"displayName":"Pathumi Ahinsa","userId":"00611856141901815530"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a9f95b0-ff55-415a-94b5-f5f351fcbe3e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2946563779.py:38: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n","  trainer = Seq2SeqTrainer(\n"]}]},{"cell_type":"code","source":["# ====================================================================\n","# STEP 7: Start Fine-Tuning (with Resume Capability)\n","# ====================================================================\n","\n","print(\"\\n5. Starting fine-tuning...\")\n","\n","# Check for the latest checkpoint in the output directory\n","import os\n","latest_checkpoint = None\n","if os.path.isdir(OUTPUT_DIR):\n","    # Find the latest checkpoint folder\n","    checkpoints = [\n","        os.path.join(OUTPUT_DIR, d)\n","        for d in os.listdir(OUTPUT_DIR)\n","        if d.startswith(\"checkpoint-\")\n","    ]\n","    if checkpoints:\n","        latest_checkpoint = max(checkpoints, key=os.path.getmtime)\n","        print(f\"Found existing checkpoint: {latest_checkpoint}. Resuming training...\")\n","\n","# Start training, resuming if a checkpoint was found\n","train_result = trainer.train(resume_from_checkpoint=latest_checkpoint)\n","\n","print(\"\\nFine-tuning complete!\")\n","\n","# Save the final model and tokenizer\n","trainer.save_model(OUTPUT_DIR)\n","tokenizer.save_pretrained(OUTPUT_DIR)\n","print(f\"Final model and tokenizer saved to: {OUTPUT_DIR}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"3HShHv6t0ZCZ","executionInfo":{"status":"error","timestamp":1764307413426,"user_tz":-330,"elapsed":7898,"user":{"displayName":"Pathumi Ahinsa","userId":"00611856141901815530"}},"outputId":"15e66dfb-19bb-455c-fd12-87b3c7fd7ea1"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","5. Starting fine-tuning...\n","Found existing checkpoint: /content/drive/MyDrive/research/model/m2m100_finetuned/checkpoint-500. Resuming training...\n"]},{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/research/model/m2m100_finetuned/checkpoint-500/trainer_state.json'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-455720402.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Start training, resuming if a checkpoint was found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFine-tuning complete!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2297\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m             \u001b[0;31m# In case of repeating the find_executable_batch_size, set `self._train_batch_size` properly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2299\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAINER_STATE_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2300\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mload_from_json\u001b[0;34m(cls, json_path)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;34m\"\"\"Create an instance from the content of `json_path`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/research/model/m2m100_finetuned/checkpoint-500/trainer_state.json'"]}]}]}