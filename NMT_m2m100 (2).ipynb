{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bf4f899556b43ebbf75d6017449a1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_799838946d584be2938fce8e727b2b76",
              "IPY_MODEL_27a22bc30443411c9e38665e8bfce35b",
              "IPY_MODEL_17d2fb52e90b4f2e95801d9d215197da"
            ],
            "layout": "IPY_MODEL_2fb506f3732d4a57b95468707997c36f"
          }
        },
        "799838946d584be2938fce8e727b2b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffca0d557d7d47c195a8d61d7d03c994",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a6143bce855f43b7a401adcb43502ee3",
            "value": "Map:‚Äá100%"
          }
        },
        "27a22bc30443411c9e38665e8bfce35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20d46730abcb407497d8196853798413",
            "max": 103437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1d9da947fe24a4d9937f80584f5d13b",
            "value": 103437
          }
        },
        "17d2fb52e90b4f2e95801d9d215197da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7c3af5b0a4847b29f731cf56ecefed8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cabaaf95a5dd4ac5b9a17e0bcebabf54",
            "value": "‚Äá103437/103437‚Äá[00:25&lt;00:00,‚Äá4811.71‚Äáexamples/s]"
          }
        },
        "2fb506f3732d4a57b95468707997c36f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffca0d557d7d47c195a8d61d7d03c994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6143bce855f43b7a401adcb43502ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20d46730abcb407497d8196853798413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d9da947fe24a4d9937f80584f5d13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7c3af5b0a4847b29f731cf56ecefed8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cabaaf95a5dd4ac5b9a17e0bcebabf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be0607caaecb43c4979cac2874028eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad93997a264d4e7cab1e57a73986c8da",
              "IPY_MODEL_c4788a15092a4feaa8734b2429480f0c",
              "IPY_MODEL_d97f5ff023094bf6b4f6bb59976be6a2"
            ],
            "layout": "IPY_MODEL_0bd741b9c6df4d9d8f55f34c43325032"
          }
        },
        "ad93997a264d4e7cab1e57a73986c8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32b7617969034274805d4efb34d9abcb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ff2a61d2bcf64706a97c0b29a2f3eaec",
            "value": "Map:‚Äá100%"
          }
        },
        "c4788a15092a4feaa8734b2429480f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71a5d97a07074bc489774f2df8926381",
            "max": 11494,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59ec2be4e5194b119faded10d79e9429",
            "value": 11494
          }
        },
        "d97f5ff023094bf6b4f6bb59976be6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa27c34e86f44d999d1bdd8daaa6a1e2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2ddb8e99feb54ebfa557779dab5f6630",
            "value": "‚Äá11494/11494‚Äá[00:02&lt;00:00,‚Äá4706.97‚Äáexamples/s]"
          }
        },
        "0bd741b9c6df4d9d8f55f34c43325032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b7617969034274805d4efb34d9abcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff2a61d2bcf64706a97c0b29a2f3eaec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71a5d97a07074bc489774f2df8926381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ec2be4e5194b119faded10d79e9429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa27c34e86f44d999d1bdd8daaa6a1e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ddb8e99feb54ebfa557779dab5f6630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ],
      "metadata": {
        "id": "y-9_UI7xaXlc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "tDmsYpU1l3mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nakd2XlpXcKN"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# STEP 0: Setup and Installation\n",
        "# ====================================================================\n",
        "\n",
        "# Install necessary libraries (if running in a fresh environment like Colab)\n",
        "# !pip install transformers datasets sentencepiece accelerate -q\n",
        "\n",
        "import torch\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    M2M100ForConditionalGeneration,\n",
        "    M2M100Tokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "\n",
        ")\n",
        "from torch.optim import AdamW   # ADD THIS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up CUDA if a GPU is available (highly recommended for Transformers)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "# torch.cuda.empty_cache() # Use this line if you encounter memory issues\n",
        "\n",
        "# Define File Path (Adjust if necessary)\n",
        "FILE_PATH = \"/content/drive/MyDrive/research/model/merged_f.txt\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/research/model/m2m100_finetuned\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fubzEsVVZtTo",
        "outputId": "0e9c9a42-2771-443e-8738-fc1d66ab5cf2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# STEP 1: Data Loading, Splitting, and Initial Dataset Creation\n",
        "# ====================================================================\n",
        "\n",
        "src_texts = []\n",
        "tgt_texts = []\n",
        "\n",
        "print(\"1. Loading and parsing data...\")\n",
        "try:\n",
        "    with open(FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if \"@\" in line:\n",
        "                parts = line.strip().split(\"@\")\n",
        "                if len(parts) == 2:\n",
        "                    # Source (Sinhala Text) is before '@'\n",
        "                    src_texts.append(parts[0].strip())\n",
        "                    # Target (Gloss IDs/Text) is after '@'\n",
        "                    tgt_texts.append(parts[1].strip())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {FILE_PATH}. Please check your path.\")\n",
        "    # Exit or use dummy data for testing if path is wrong\n",
        "\n",
        "print(f\"Total samples loaded: {len(src_texts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_ZSdy6JZZ_V",
        "outputId": "04d65e4a-b6af-4e40-9e64-3cc8110000e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Loading and parsing data...\n",
            "Total samples loaded: 114931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data: 90% Train, 10% Eval\n",
        "train_src, eval_src, train_tgt, eval_tgt = train_test_split(\n",
        "    src_texts, tgt_texts, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "# Create Hugging Face Dataset objects\n",
        "train_dataset = Dataset.from_dict({\"source\": train_src, \"target\": train_tgt})\n",
        "eval_dataset = Dataset.from_dict({\"source\": eval_src, \"target\": eval_tgt})\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Evaluation samples: {len(eval_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5wXIaEj6BcE",
        "outputId": "ddc5b0a6-a004-4573-f099-3470016105e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 103437\n",
            "Evaluation samples: 11494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "\n",
        "# 1. Define a permanent path in your Google Drive\n",
        "# This is where the base model files will sit\n",
        "model_save_path = \"/content/drive/MyDrive/research/model/m2m100_base_saved\"\n",
        "\n",
        "MODEL_NAME = \"facebook/m2m100_418M\"\n",
        "print(f\"\\n2. Initializing model...\")\n",
        "\n",
        "# 2. Check if the model already exists in your Drive\n",
        "if os.path.exists(model_save_path):\n",
        "    print(f\"üìÇ Found saved model in Drive. Loading from: {model_save_path}\")\n",
        "    # Load directly from Drive (Fast!)\n",
        "    model = M2M100ForConditionalGeneration.from_pretrained(model_save_path).to(device)\n",
        "    tokenizer = M2M100Tokenizer.from_pretrained(model_save_path)\n",
        "\n",
        "else:\n",
        "    print(f\"‚¨áÔ∏è Model not found in Drive. Downloading from Hugging Face: {MODEL_NAME}\")\n",
        "    # Download from Internet\n",
        "    model = M2M100ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
        "    tokenizer = M2M100Tokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    # Save to Drive for next time\n",
        "    print(f\"üíæ Saving model to Drive for future use...\")\n",
        "    model.save_pretrained(model_save_path)\n",
        "    tokenizer.save_pretrained(model_save_path)\n",
        "\n",
        "# 3. Set Languages\n",
        "# We explicitly set these every time just to be safe\n",
        "tokenizer.src_lang = \"si\"\n",
        "tokenizer.tgt_lang = \"si\"\n",
        "print(f\"Tokenizer set for src_lang: {tokenizer.src_lang} and tgt_lang: {tokenizer.tgt_lang}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYjccOFAX9Om",
        "outputId": "816c49e7-1d28-4632-ef9c-300a0748cc63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. Initializing model...\n",
            "üìÇ Found saved model in Drive. Loading from: /content/drive/MyDrive/research/model/m2m100_base_saved\n",
            "Tokenizer set for src_lang: si and tgt_lang: si\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# STEP 3: Vocabulary Adaptation for Target Gloss Tokens\n",
        "# (Crucial for handling the SSL/Gloss output)\n",
        "# ====================================================================\n",
        "\n",
        "print(\"\\n3. Adapting vocabulary for Gloss tokens...\")\n",
        "\n",
        "# 3.1 Extract unique Gloss Tokens from your target data\n",
        "unique_gloss_tokens = set()\n",
        "all_tgt_texts = train_tgt + eval_tgt\n",
        "\n",
        "for text in all_tgt_texts:\n",
        "    # Target format: 'ID:GLOSS_WORD|ID:GLOSS_WORD|...'\n",
        "    parts = text.split('|')\n",
        "    for part in parts:\n",
        "        if ':' in part:\n",
        "            # Take everything after the first ':' (which is the Gloss word)\n",
        "            gloss_token = part.split(':', 1)[1]\n",
        "            unique_gloss_tokens.add(gloss_token.strip())\n",
        "\n",
        "unique_gloss_tokens_list = list(unique_gloss_tokens)\n",
        "print(f\"Identified {len(unique_gloss_tokens_list)} unique Gloss tokens.\")\n",
        "\n",
        "# 3.2 Add new tokens and resize model embeddings\n",
        "num_added_toks = tokenizer.add_tokens(unique_gloss_tokens_list)\n",
        "print(f\"Added {num_added_toks} new tokens to the tokenizer.\")\n",
        "\n",
        "# Resize the model embeddings to include the new tokens.\n",
        "# The new embeddings for these tokens are randomly initialized.\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "print(f\"Model vocabulary size resized to: {len(tokenizer)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIeKBpA_aS1z",
        "outputId": "4c50147d-ccaf-4a46-960f-b8840ffe838d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Adapting vocabulary for Gloss tokens...\n",
            "Identified 3479 unique Gloss tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 3410 new tokens to the tokenizer.\n",
            "Model vocabulary size resized to: 131514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# STEP 4: Tokenization Function and Dataset Mapping\n",
        "# ====================================================================\n",
        "\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples[\"source\"]\n",
        "    targets = examples[\"target\"]\n",
        "\n",
        "    # Tokenize inputs (Source - Sinhala Text)\n",
        "    model_inputs = tokenizer(inputs, max_length=MAX_SEQ_LENGTH, truncation=True)\n",
        "\n",
        "    # Tokenize targets (Labels - Gloss Text)\n",
        "    # The context manager ensures the tokenizer uses the target language settings.\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=MAX_SEQ_LENGTH, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Apply tokenization to datasets\n",
        "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_eval = eval_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Remove original columns that are no longer needed\n",
        "tokenized_train = tokenized_train.remove_columns([\"source\", \"target\"])\n",
        "tokenized_eval = tokenized_eval.remove_columns([\"source\", \"target\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "4bf4f899556b43ebbf75d6017449a1f2",
            "799838946d584be2938fce8e727b2b76",
            "27a22bc30443411c9e38665e8bfce35b",
            "17d2fb52e90b4f2e95801d9d215197da",
            "2fb506f3732d4a57b95468707997c36f",
            "ffca0d557d7d47c195a8d61d7d03c994",
            "a6143bce855f43b7a401adcb43502ee3",
            "20d46730abcb407497d8196853798413",
            "c1d9da947fe24a4d9937f80584f5d13b",
            "a7c3af5b0a4847b29f731cf56ecefed8",
            "cabaaf95a5dd4ac5b9a17e0bcebabf54",
            "be0607caaecb43c4979cac2874028eca",
            "ad93997a264d4e7cab1e57a73986c8da",
            "c4788a15092a4feaa8734b2429480f0c",
            "d97f5ff023094bf6b4f6bb59976be6a2",
            "0bd741b9c6df4d9d8f55f34c43325032",
            "32b7617969034274805d4efb34d9abcb",
            "ff2a61d2bcf64706a97c0b29a2f3eaec",
            "71a5d97a07074bc489774f2df8926381",
            "59ec2be4e5194b119faded10d79e9429",
            "fa27c34e86f44d999d1bdd8daaa6a1e2",
            "2ddb8e99feb54ebfa557779dab5f6630"
          ]
        },
        "id": "3RYLxQRRaWzn",
        "outputId": "2336aebd-2e6f-4d2e-f8aa-c9a137dd71aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/103437 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bf4f899556b43ebbf75d6017449a1f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4118: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11494 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be0607caaecb43c4979cac2874028eca"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# STEP 5: Differential Learning Rate Configuration\n",
        "# (Implementing the paper's strategy)\n",
        "# ====================================================================\n",
        "\n",
        "print(\"\\n4. Configuring Differential Learning Rates...\")\n",
        "\n",
        "# Differential LRs based on the paper:\n",
        "LR_NEW_WEIGHTS = 1.0e-3 # For newly initialized/resized embeddings and output head\n",
        "LR_PRE_TRAINED = 2.0e-5 # For the core pre-trained layers (Encoder/Decoder)\n",
        "\n",
        "# Separate parameters into two groups\n",
        "# Group 1: Pre-trained layers (core Encoder/Decoder) -> SMALL LR\n",
        "pretrained_params = [\n",
        "    p for n, p in model.named_parameters() if p.requires_grad and not any(ext in n for ext in [\"embed\", \"lm_head\"])\n",
        "]\n",
        "\n",
        "# Group 2: Newly resized embeddings and output head -> LARGER LR\n",
        "# 'embed' for input/output embeddings, 'lm_head' for the final classification layer\n",
        "new_params = [\n",
        "    p for n, p in model.named_parameters() if p.requires_grad and any(ext in n for ext in [\"embed\", \"lm_head\"])\n",
        "]\n",
        "\n",
        "# Define the parameter groups for the optimizer\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        \"params\": pretrained_params,\n",
        "        \"lr\": LR_PRE_TRAINED,\n",
        "        \"weight_decay\": 0.01\n",
        "    },\n",
        "    {\n",
        "        \"params\": new_params,\n",
        "        \"lr\": LR_NEW_WEIGHTS,\n",
        "        \"weight_decay\": 0.01\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "877ct_Zfc-2X",
        "outputId": "fa582d09-ff49-4fdb-fea6-ab287ddc369c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4. Configuring Differential Learning Rates...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# STEP 6: Setup Trainer Arguments and Initialization\n",
        "# ====================================================================\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "NUM_EPOCHS = 10\n",
        "SAVE_STEPS = 500\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Training Arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=8, # <--- ADD GRADIENT ACCUMULATION (4 * 8 = 32 effective)\n",
        "    warmup_ratio=5/NUM_EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    report_to=\"none\",\n",
        "\n",
        "    # Checkpointing Configuration\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=SAVE_STEPS,\n",
        "    save_total_limit=3,\n",
        "    eval_strategy=\"epoch\",\n",
        "    load_best_model_at_end=False,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    predict_with_generate=True,\n",
        "    learning_rate=LR_PRE_TRAINED,\n",
        "    safe_serialization=True\n",
        ")\n",
        "\n",
        "# Initialize Trainer.\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    tokenizer=tokenizer,\n",
        "    # processing_class=M2M100Tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    # Ensure you imported AdamW from torch.optim as discussed before\n",
        "    optimizers=(AdamW(optimizer_grouped_parameters, eps=1e-6), None),\n",
        ")"
      ],
      "metadata": {
        "id": "Wx1QEy2_xZTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "959427e9-fba6-4628-bc8e-8c8c09f08964"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2946563779.py:38: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# STEP 7: Start Fine-Tuning (with Resume Capability)\n",
        "# ====================================================================\n",
        "\n",
        "print(\"\\n5. Starting fine-tuning...\")\n",
        "\n",
        "# Check for the latest checkpoint in the output directory\n",
        "import os\n",
        "latest_checkpoint = None\n",
        "if os.path.isdir(OUTPUT_DIR):\n",
        "    # Find the latest checkpoint folder\n",
        "    checkpoints = [\n",
        "        os.path.join(OUTPUT_DIR, d)\n",
        "        for d in os.listdir(OUTPUT_DIR)\n",
        "        if d.startswith(\"checkpoint-\")\n",
        "    ]\n",
        "    if checkpoints:\n",
        "        latest_checkpoint = max(checkpoints, key=os.path.getmtime)\n",
        "        print(f\"Found existing checkpoint: {latest_checkpoint}. Resuming training...\")\n",
        "\n",
        "# Start training, resuming if a checkpoint was found\n",
        "train_result = trainer.train(resume_from_checkpoint=latest_checkpoint)\n",
        "\n",
        "print(\"\\nFine-tuning complete!\")\n",
        "\n",
        "# Save the final model and tokenizer\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "print(f\"Final model and tokenizer saved to: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "3HShHv6t0ZCZ",
        "outputId": "6d4b08d5-7174-4565-8145-459d1035a97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. Starting fine-tuning...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='32330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   34/32330 00:42 < 12:03:09, 0.74 it/s, Epoch 0.01/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}