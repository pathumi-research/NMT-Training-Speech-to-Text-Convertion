{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1WOaJIQ_BXc58CQ6DMr14RxSJcQtZ-eow",
      "authorship_tag": "ABX9TyOk+s+iqfXfVUqbhdiwqs7x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3853ae639c58486782f712562dfe2eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c6fcf9d5b7b440d9b2c1d4d24c3fc92",
              "IPY_MODEL_11f0e48083e44f659207a7839eb44f84",
              "IPY_MODEL_db69d74d6def4fe5aca59ca721239734"
            ],
            "layout": "IPY_MODEL_4fa25ee008d84042a29944e021edcdcc"
          }
        },
        "6c6fcf9d5b7b440d9b2c1d4d24c3fc92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b91a5feffc134aafbea64476fefd9c2b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_29e29d609c4c4f0582caac28d6a99653",
            "value": "Map:‚Äá100%"
          }
        },
        "11f0e48083e44f659207a7839eb44f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcbca39ff5fd493dba071e681bf3e82b",
            "max": 103437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_710859ce66d5401a91c8d2110d53a426",
            "value": 103437
          }
        },
        "db69d74d6def4fe5aca59ca721239734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9426a7d46a5c4c9c88bfba607704cb3a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d2f2929c40fa4a74817be9f0ba8fd26a",
            "value": "‚Äá103437/103437‚Äá[00:31&lt;00:00,‚Äá3661.16‚Äáexamples/s]"
          }
        },
        "4fa25ee008d84042a29944e021edcdcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b91a5feffc134aafbea64476fefd9c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29e29d609c4c4f0582caac28d6a99653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcbca39ff5fd493dba071e681bf3e82b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "710859ce66d5401a91c8d2110d53a426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9426a7d46a5c4c9c88bfba607704cb3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2f2929c40fa4a74817be9f0ba8fd26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c233c1fa1ad449f9c24e3bc03afb534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d12cd104f5349c98b901ae252275efd",
              "IPY_MODEL_2f89f508494f45e5a452a4044f5d9c4f",
              "IPY_MODEL_fa04c4fb97204078bad4c45b0fefed58"
            ],
            "layout": "IPY_MODEL_45479f9f86074890b6a120e51c39bccb"
          }
        },
        "4d12cd104f5349c98b901ae252275efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f95104eccfde44f092b1dca31da80a9c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_363bde165dc44a83933b2d177524b9e5",
            "value": "Map:‚Äá100%"
          }
        },
        "2f89f508494f45e5a452a4044f5d9c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ea4cf90a1f74f56898cc09860c66f9c",
            "max": 11494,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46ec9a97f1394bacae12392950dcd3a6",
            "value": 11494
          }
        },
        "fa04c4fb97204078bad4c45b0fefed58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f72b71399354a4ebba99a4934bbba86",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d90d25a5d2be4d30a840349905fb6fa4",
            "value": "‚Äá11494/11494‚Äá[00:04&lt;00:00,‚Äá3241.65‚Äáexamples/s]"
          }
        },
        "45479f9f86074890b6a120e51c39bccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f95104eccfde44f092b1dca31da80a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363bde165dc44a83933b2d177524b9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ea4cf90a1f74f56898cc09860c66f9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ec9a97f1394bacae12392950dcd3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f72b71399354a4ebba99a4934bbba86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d90d25a5d2be4d30a840349905fb6fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pathu11/NMT-Training-Speech-to-Text-Convertion/blob/main/NMT_m2m100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nakd2XlpXcKN"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# STEP 0: Setup and Installation\n",
        "# ====================================================================\n",
        "\n",
        "# Install necessary libraries (if running in a fresh environment like Colab)\n",
        "# !pip install transformers datasets sentencepiece accelerate -q\n",
        "\n",
        "import torch\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    M2M100ForConditionalGeneration,\n",
        "    M2M100Tokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "\n",
        ")\n",
        "from torch.optim import AdamW   # ADD THIS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up CUDA if a GPU is available (highly recommended for Transformers)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "# torch.cuda.empty_cache() # Use this line if you encounter memory issues\n",
        "\n",
        "# Define File Path (Adjust if necessary)\n",
        "FILE_PATH = \"/content/drive/MyDrive/research/model/merged_f.txt\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/research/model/m2m100_finetuned\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fubzEsVVZtTo",
        "outputId": "fd667e2f-6315-4d1f-f5d3-dce003c23ef1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# STEP 1: Data Loading, Splitting, and Initial Dataset Creation\n",
        "# ====================================================================\n",
        "\n",
        "src_texts = []\n",
        "tgt_texts = []\n",
        "\n",
        "print(\"1. Loading and parsing data...\")\n",
        "try:\n",
        "    with open(FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if \"@\" in line:\n",
        "                parts = line.strip().split(\"@\")\n",
        "                if len(parts) == 2:\n",
        "                    # Source (Sinhala Text) is before '@'\n",
        "                    src_texts.append(parts[0].strip())\n",
        "                    # Target (Gloss IDs/Text) is after '@'\n",
        "                    tgt_texts.append(parts[1].strip())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {FILE_PATH}. Please check your path.\")\n",
        "    # Exit or use dummy data for testing if path is wrong\n",
        "\n",
        "print(f\"Total samples loaded: {len(src_texts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_ZSdy6JZZ_V",
        "outputId": "1fbefbfa-7dbb-4038-c610-1301d0629cdf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Loading and parsing data...\n",
            "Total samples loaded: 114931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data: 90% Train, 10% Eval\n",
        "train_src, eval_src, train_tgt, eval_tgt = train_test_split(\n",
        "    src_texts, tgt_texts, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "# Create Hugging Face Dataset objects\n",
        "train_dataset = Dataset.from_dict({\"source\": train_src, \"target\": train_tgt})\n",
        "eval_dataset = Dataset.from_dict({\"source\": eval_src, \"target\": eval_tgt})\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Evaluation samples: {len(eval_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5wXIaEj6BcE",
        "outputId": "d230623b-ed8b-4f0b-dfd7-46addc61e736"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 103437\n",
            "Evaluation samples: 11494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "\n",
        "# 1. Define a permanent path in your Google Drive\n",
        "# This is where the base model files will sit\n",
        "model_save_path = \"/content/drive/MyDrive/research/model/m2m100_base_saved\"\n",
        "\n",
        "MODEL_NAME = \"facebook/m2m100_418M\"\n",
        "print(f\"\\n2. Initializing model...\")\n",
        "\n",
        "# 2. Check if the model already exists in your Drive\n",
        "if os.path.exists(model_save_path):\n",
        "    print(f\"üìÇ Found saved model in Drive. Loading from: {model_save_path}\")\n",
        "    # Load directly from Drive (Fast!)\n",
        "    model = M2M100ForConditionalGeneration.from_pretrained(model_save_path).to(device)\n",
        "    tokenizer = M2M100Tokenizer.from_pretrained(model_save_path)\n",
        "\n",
        "else:\n",
        "    print(f\"‚¨áÔ∏è Model not found in Drive. Downloading from Hugging Face: {MODEL_NAME}\")\n",
        "    # Download from Internet\n",
        "    model = M2M100ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
        "    tokenizer = M2M100Tokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    # Save to Drive for next time\n",
        "    print(f\"üíæ Saving model to Drive for future use...\")\n",
        "    model.save_pretrained(model_save_path)\n",
        "    tokenizer.save_pretrained(model_save_path)\n",
        "\n",
        "# 3. Set Languages\n",
        "# We explicitly set these every time just to be safe\n",
        "tokenizer.src_lang = \"si\"\n",
        "tokenizer.tgt_lang = \"si\"\n",
        "print(f\"Tokenizer set for src_lang: {tokenizer.src_lang} and tgt_lang: {tokenizer.tgt_lang}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYjccOFAX9Om",
        "outputId": "13b8746c-3924-4401-a8a0-3446b1de74b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. Initializing model...\n",
            "üìÇ Found saved model in Drive. Loading from: /content/drive/MyDrive/research/model/m2m100_base_saved\n",
            "Tokenizer set for src_lang: si and tgt_lang: si\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# STEP 3: Vocabulary Adaptation for Target Gloss Tokens\n",
        "# (Crucial for handling the SSL/Gloss output)\n",
        "# ====================================================================\n",
        "\n",
        "print(\"\\n3. Adapting vocabulary for Gloss tokens...\")\n",
        "\n",
        "# 3.1 Extract unique Gloss Tokens from your target data\n",
        "unique_gloss_tokens = set()\n",
        "all_tgt_texts = train_tgt + eval_tgt\n",
        "\n",
        "for text in all_tgt_texts:\n",
        "    # Target format: 'ID:GLOSS_WORD|ID:GLOSS_WORD|...'\n",
        "    parts = text.split('|')\n",
        "    for part in parts:\n",
        "        if ':' in part:\n",
        "            # Take everything after the first ':' (which is the Gloss word)\n",
        "            gloss_token = part.split(':', 1)[1]\n",
        "            unique_gloss_tokens.add(gloss_token.strip())\n",
        "\n",
        "unique_gloss_tokens_list = list(unique_gloss_tokens)\n",
        "print(f\"Identified {len(unique_gloss_tokens_list)} unique Gloss tokens.\")\n",
        "\n",
        "# 3.2 Add new tokens and resize model embeddings\n",
        "num_added_toks = tokenizer.add_tokens(unique_gloss_tokens_list)\n",
        "print(f\"Added {num_added_toks} new tokens to the tokenizer.\")\n",
        "\n",
        "# Resize the model embeddings to include the new tokens.\n",
        "# The new embeddings for these tokens are randomly initialized.\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "print(f\"Model vocabulary size resized to: {len(tokenizer)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIeKBpA_aS1z",
        "outputId": "7d7707e3-4fd4-4341-ff8f-fc1d25e6c0b2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Adapting vocabulary for Gloss tokens...\n",
            "Identified 3479 unique Gloss tokens.\n",
            "Added 0 new tokens to the tokenizer.\n",
            "Model vocabulary size resized to: 131514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# STEP 4: Tokenization Function and Dataset Mapping\n",
        "# ====================================================================\n",
        "\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples[\"source\"]\n",
        "    targets = examples[\"target\"]\n",
        "\n",
        "    # Tokenize inputs (Source - Sinhala Text)\n",
        "    model_inputs = tokenizer(inputs, max_length=MAX_SEQ_LENGTH, truncation=True)\n",
        "\n",
        "    # Tokenize targets (Labels - Gloss Text)\n",
        "    # The context manager ensures the tokenizer uses the target language settings.\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=MAX_SEQ_LENGTH, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Apply tokenization to datasets\n",
        "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_eval = eval_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Remove original columns that are no longer needed\n",
        "tokenized_train = tokenized_train.remove_columns([\"source\", \"target\"])\n",
        "tokenized_eval = tokenized_eval.remove_columns([\"source\", \"target\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "3853ae639c58486782f712562dfe2eb7",
            "6c6fcf9d5b7b440d9b2c1d4d24c3fc92",
            "11f0e48083e44f659207a7839eb44f84",
            "db69d74d6def4fe5aca59ca721239734",
            "4fa25ee008d84042a29944e021edcdcc",
            "b91a5feffc134aafbea64476fefd9c2b",
            "29e29d609c4c4f0582caac28d6a99653",
            "bcbca39ff5fd493dba071e681bf3e82b",
            "710859ce66d5401a91c8d2110d53a426",
            "9426a7d46a5c4c9c88bfba607704cb3a",
            "d2f2929c40fa4a74817be9f0ba8fd26a",
            "8c233c1fa1ad449f9c24e3bc03afb534",
            "4d12cd104f5349c98b901ae252275efd",
            "2f89f508494f45e5a452a4044f5d9c4f",
            "fa04c4fb97204078bad4c45b0fefed58",
            "45479f9f86074890b6a120e51c39bccb",
            "f95104eccfde44f092b1dca31da80a9c",
            "363bde165dc44a83933b2d177524b9e5",
            "9ea4cf90a1f74f56898cc09860c66f9c",
            "46ec9a97f1394bacae12392950dcd3a6",
            "4f72b71399354a4ebba99a4934bbba86",
            "d90d25a5d2be4d30a840349905fb6fa4"
          ]
        },
        "id": "3RYLxQRRaWzn",
        "outputId": "e74a485a-b006-4ad7-e6e1-8fabec91c7e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/103437 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3853ae639c58486782f712562dfe2eb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11494 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c233c1fa1ad449f9c24e3bc03afb534"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# STEP 5: Differential Learning Rate Configuration\n",
        "# (Implementing the paper's strategy)\n",
        "# ====================================================================\n",
        "\n",
        "print(\"\\n4. Configuring Differential Learning Rates...\")\n",
        "\n",
        "# Differential LRs based on the paper:\n",
        "LR_NEW_WEIGHTS = 1.0e-3 # For newly initialized/resized embeddings and output head\n",
        "LR_PRE_TRAINED = 2.0e-5 # For the core pre-trained layers (Encoder/Decoder)\n",
        "\n",
        "# Separate parameters into two groups\n",
        "# Group 1: Pre-trained layers (core Encoder/Decoder) -> SMALL LR\n",
        "pretrained_params = [\n",
        "    p for n, p in model.named_parameters() if p.requires_grad and not any(ext in n for ext in [\"embed\", \"lm_head\"])\n",
        "]\n",
        "\n",
        "# Group 2: Newly resized embeddings and output head -> LARGER LR\n",
        "# 'embed' for input/output embeddings, 'lm_head' for the final classification layer\n",
        "new_params = [\n",
        "    p for n, p in model.named_parameters() if p.requires_grad and any(ext in n for ext in [\"embed\", \"lm_head\"])\n",
        "]\n",
        "\n",
        "# Define the parameter groups for the optimizer\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        \"params\": pretrained_params,\n",
        "        \"lr\": LR_PRE_TRAINED,\n",
        "        \"weight_decay\": 0.01\n",
        "    },\n",
        "    {\n",
        "        \"params\": new_params,\n",
        "        \"lr\": LR_NEW_WEIGHTS,\n",
        "        \"weight_decay\": 0.01\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "877ct_Zfc-2X",
        "outputId": "f37d2204-e684-43b8-d423-b30ded4a50c3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4. Configuring Differential Learning Rates...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# STEP 6: Setup Trainer Arguments and Initialization\n",
        "# ====================================================================\n",
        "\n",
        "BATCH_SIZE = 50\n",
        "NUM_EPOCHS = 10\n",
        "SAVE_STEPS = 500\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Training Arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    warmup_ratio=5/NUM_EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    report_to=\"none\",\n",
        "\n",
        "    # Checkpointing Configuration\n",
        "    save_strategy=\"epoch\",\n",
        "    save_steps=SAVE_STEPS,\n",
        "    save_total_limit=3,\n",
        "    eval_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    predict_with_generate=True,\n",
        "\n",
        "    learning_rate=LR_PRE_TRAINED,\n",
        ")\n",
        "\n",
        "# Initialize Trainer.\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    processing_class=M2M100Tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    # Ensure you imported AdamW from torch.optim as discussed before\n",
        "    optimizers=(AdamW(optimizer_grouped_parameters, eps=1e-6), None),\n",
        ")"
      ],
      "metadata": {
        "id": "Wx1QEy2_xZTt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# STEP 7: Start Fine-Tuning (with Resume Capability)\n",
        "# ====================================================================\n",
        "\n",
        "print(\"\\n5. Starting fine-tuning...\")\n",
        "\n",
        "# Check for the latest checkpoint in the output directory\n",
        "import os\n",
        "latest_checkpoint = None\n",
        "if os.path.isdir(OUTPUT_DIR):\n",
        "    # Find the latest checkpoint folder\n",
        "    checkpoints = [\n",
        "        os.path.join(OUTPUT_DIR, d)\n",
        "        for d in os.listdir(OUTPUT_DIR)\n",
        "        if d.startswith(\"checkpoint-\")\n",
        "    ]\n",
        "    if checkpoints:\n",
        "        latest_checkpoint = max(checkpoints, key=os.path.getmtime)\n",
        "        print(f\"Found existing checkpoint: {latest_checkpoint}. Resuming training...\")\n",
        "\n",
        "# Start training, resuming if a checkpoint was found\n",
        "train_result = trainer.train(resume_from_checkpoint=latest_checkpoint)\n",
        "\n",
        "print(\"\\nFine-tuning complete!\")\n",
        "\n",
        "# Save the final model and tokenizer\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "print(f\"Final model and tokenizer saved to: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HShHv6t0ZCZ",
        "outputId": "74e120de-6697-405b-ed93-ffbbcb9bac93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. Starting fine-tuning...\n"
          ]
        }
      ]
    }
  ]
}